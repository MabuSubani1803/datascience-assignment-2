{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Importing Dataset\n",
    "\n",
    "# Importing Training and Testing Dataset\n",
    "salary_train = pd.read_csv('D:/Assignment and data set/SalaryData_Train(1).csv')\n",
    "salary_train\n",
    "\n",
    "salary_test = pd.read_csv('D:/Assignment and data set/SalaryData_Test(1).csv')\n",
    "salary_test\n",
    "\n",
    "# Merging Train and Test Data\n",
    "raw_data = salary_train.append(salary_test)\n",
    "raw_data.reset_index(inplace=True,drop=True)\n",
    "raw_data\n",
    "\n",
    "#Data Exploration\n",
    "#Descriptive Statistics\n",
    "raw_data.describe()\n",
    "raw_data.info()\n",
    "#Missing Values\n",
    "raw_data.isnull().sum()\n",
    "#Duplicated Values\n",
    "raw_data.duplicated().sum()\n",
    "#columns\n",
    "raw_data.columns\n",
    "\n",
    "#Numerical Variables\n",
    "# List of Numerical Variables\n",
    "numerical_features=[feature for feature in raw_data.columns if raw_data[feature].dtypes != 'O']\n",
    "\n",
    "print('Number of numerical variables:', len(numerical_features))\n",
    "\n",
    "# Visualize the numerical variables\n",
    "raw_data[numerical_features].head()\n",
    "\n",
    "#Discrete Feature\n",
    "discrete_feature=[feature for feature in numerical_features if len(raw_data[feature].unique())<25]\n",
    "print('Discrete Variables Count: {}'.format(len(discrete_feature)))\n",
    "\n",
    "#Continuous Variable\n",
    "continuous_feature=[feature for feature in numerical_features if feature not in discrete_feature]\n",
    "print('Continuous Feature Count {}'.format(len(continuous_feature)))\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig= plt.figure(figsize=(18, 8))\n",
    "sns.heatmap(raw_data.corr(), annot=True);\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "\n",
    "#Outliers Detection\n",
    "ot=raw_data.copy() \n",
    "fig, axes=plt.subplots(4,1,figsize=(14,8),sharex=False,sharey=False)\n",
    "sns.boxplot(x='age',data=ot,palette='crest',ax=axes[0])\n",
    "sns.boxplot(x='capitalgain',data=ot,palette='crest',ax=axes[1])\n",
    "sns.boxplot(x='capitalloss',data=ot,palette='crest',ax=axes[2])\n",
    "sns.boxplot(x='hoursperweek',data=ot,palette='crest',ax=axes[3])\n",
    "plt.tight_layout(pad=2.0)\n",
    "\n",
    "#After Log-Transformation\n",
    "for feature in continuous_feature:\n",
    "    data=raw_data.copy()\n",
    "    data[feature]=np.log(data[feature])\n",
    "    data.boxplot(column=feature)\n",
    "    plt.ylabel(feature)\n",
    "    plt.title(feature)\n",
    "    plt.show()\n",
    "\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.pie(raw_data['Salary'].value_counts(),\n",
    "       labels=raw_data.Salary.unique(),\n",
    "       explode = [0.07,0.0],\n",
    "       autopct= '%.2f%%',\n",
    "        colors = [\"#F96167\", \"#FCE77D\"],\n",
    "       shadow= True,\n",
    "       startangle= 190,\n",
    "       textprops = {'size':'large',\n",
    "                   'fontweight':'bold',\n",
    "                    'rotation':'0',\n",
    "                   'color':'black'})\n",
    "plt.legend(loc= 'upper right')\n",
    "plt.title(\"Class Type Distribution Pie Chart\", fontsize = 18, fontweight = 'bold')\n",
    "plt.show()\n",
    "\n",
    "#Data Pre-Processing\n",
    "#Label Encoding Technique\n",
    "from sklearn import preprocessing\n",
    " \n",
    "# label_encoder object knows how to understand word labels.\n",
    "df= raw_data.copy()\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "df[\"education\"]=label_encoder.fit_transform(df[\"education\"])\n",
    "df[\"workclass\"]=label_encoder.fit_transform(df[\"workclass\"])\n",
    "df[\"maritalstatus\"]=label_encoder.fit_transform(df[\"maritalstatus\"])\n",
    "df[\"sex\"]=label_encoder.fit_transform(df[\"sex\"])\n",
    "df[\"race\"]=label_encoder.fit_transform(df[\"race\"])\n",
    "df[\"occupation\"]=label_encoder.fit_transform(df[\"occupation\"])\n",
    "df[\"relationship\"]=label_encoder.fit_transform(df[\"relationship\"])\n",
    "df[\"native\"]=label_encoder.fit_transform(df[\"native\"])\n",
    "df.head(10)\n",
    "\n",
    "df['Salary'] = raw_data.Salary\n",
    "df['Salary'] = np.where(df['Salary'].str.contains(\" >50K\"), 1, 0)\n",
    "df.head()\n",
    "\n",
    "#Applying Standard Scaler\n",
    "df[continuous_feature]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "features = df[continuous_feature]\n",
    "df[continuous_feature] = scaler.fit_transform(features.values)\n",
    "df.head()\n",
    "\n",
    "#Test Train Split With Imbalanced Dataset\n",
    "x = df.drop('Salary',axis=1)\n",
    "y = df['Salary']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=1,stratify=y)\n",
    "\n",
    "print(\"Shape of X_train: \",x_train.shape)\n",
    "print(\"Shape of X_test: \", x_test.shape)\n",
    "print(\"Shape of y_train: \",y_train.shape)\n",
    "print(\"Shape of y_test\",y_test.shape)\n",
    "\n",
    "# Sklearn Support Vector Classifier Using Linear, Polynomial and RBF Kernel, \n",
    "''' For support vector classifier we have three types of kernals which are \n",
    "linear,poly,rbf .we will fit 3 svm model based on their kernals'''\n",
    "\n",
    "#### Support Vector classifier \n",
    "### Kernal='linear'\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='linear',C=5.0)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "### Y predictions\n",
    "Y_pred_train = clf.predict(x_train)\n",
    "Y_pred_test  = clf.predict(x_test)\n",
    "\n",
    "### accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "ac1 = accuracy_score(y_train, Y_pred_train)\n",
    "print(\"Training Accuracy score:\", (ac1*100).round(2))\n",
    "ac2 = accuracy_score(y_test, Y_pred_test)\n",
    "print(\"Test Accuracy score:\", (ac2*100).round(2))\n",
    "print('Variaance between test and train accuracy',(ac1-ac2).round(2))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix as cm, accuracy_score as ac, classification_report as report,\\\n",
    "roc_curve, roc_auc_score , recall_score , precision_score, f1_score\n",
    "\n",
    "# plot confusion matrix to describe the performance of classifier.\n",
    "cm_df=cm(y_test, Y_pred_test)\n",
    "class_label = [\"No\", \"Yes\"]\n",
    "df_cm = pd.DataFrame(cm_df, index = class_label, columns = class_label)\n",
    "sns.heatmap(df_cm, annot = True, fmt = \"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.show()\n",
    "\n",
    "#ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, Y_pred_test)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, linewidth=2, color='red')\n",
    "plt.plot([0,1], [0,1], 'k--' )\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for SVM Classifier using Polynomial Kernel for Predicting Size_category')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.show()\n",
    "ROC_AUC = roc_auc_score(y_test,Y_pred_test)\n",
    "\n",
    "print('ROC AUC : {:.4f}'.format(ROC_AUC))\n",
    "\n",
    "\n",
    "#Support Vector classifier\n",
    "#Kernal='Poly\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='poly',degree=5.0)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "### Y prediictions\n",
    "Y_pred_train = clf.predict(x_train)\n",
    "Y_pred_test  = clf.predict(x_test)\n",
    "\n",
    "### accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "ac1 = accuracy_score(y_train, Y_pred_train)\n",
    "print(\"Training Accuracy score:\", (ac1*100).round(2))\n",
    "ac2 = accuracy_score(y_test, Y_pred_test)\n",
    "print(\"Test Accuracy score:\", (ac2*100).round(2))\n",
    "print('Variaance between test and train accuracy',(ac1-ac2).round(2))\n",
    "\n",
    "# plot confusion matrix to describe the performance of classifier.\n",
    "cm_df=cm(y_test, Y_pred_test)\n",
    "class_label = [\"No\", \"Yes\"]\n",
    "df_cm = pd.DataFrame(cm_df, index = class_label, columns = class_label)\n",
    "sns.heatmap(df_cm, annot = True, fmt = \"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.show()\n",
    "\n",
    "#ROC Curve\n",
    "from sklearn.metrics import confusion_matrix as cm, accuracy_score as ac, classification_report as report,\\\n",
    "roc_curve, roc_auc_score , recall_score , precision_score, f1_score\n",
    "fpr, tpr, thresholds = roc_curve(y_test, Y_pred_test)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, linewidth=2, color='red')\n",
    "plt.plot([0,1], [0,1], 'k--' )\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for SVM Classifier using Polynomial Kernel for Predicting Size_category')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.show()\n",
    "ROC_AUC = roc_auc_score(y_test,Y_pred_test)\n",
    "\n",
    "print('ROC AUC : {:.4f}'.format(ROC_AUC))\n",
    "\n",
    "#### Support Vector classifier\n",
    "### Kernal=rbf\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='rbf',gamma='scale')\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "### Y predictions\n",
    "Y_pred_train = clf.predict(x_train)\n",
    "Y_pred_test  = clf.predict(x_test)\n",
    "\n",
    "# accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "ac1 = accuracy_score(y_train, Y_pred_train)\n",
    "print(\"Training Accuracy score:\", (ac1*100).round(2))\n",
    "ac2 = accuracy_score(y_test, Y_pred_test)\n",
    "print(\"Test Accuracy score:\", (ac2*100).round(2))\n",
    "print('Variaance between test and train accuracy',(ac1-ac2).round(2))\n",
    "\n",
    "# plot confusion matrix to describe the performance of classifier.\n",
    "cm_df=cm(y_test, Y_pred_test)\n",
    "class_label = [\"No\", \"Yes\"]\n",
    "df_cm = pd.DataFrame(cm_df, index = class_label, columns = class_label)\n",
    "sns.heatmap(df_cm, annot = True, fmt = \"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.show()\n",
    "\n",
    "#ROC Curve\n",
    "from sklearn.metrics import confusion_matrix as cm, accuracy_score as ac, classification_report as report,\\\n",
    "roc_curve, roc_auc_score , recall_score , precision_score, f1_score\n",
    "fpr, tpr, thresholds = roc_curve(y_test, Y_pred_test)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, linewidth=2, color='red')\n",
    "plt.plot([0,1], [0,1], 'k--' )\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for SVM Classifier using Polynomial Kernel for Predicting Size_category')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.show()\n",
    "ROC_AUC = roc_auc_score(y_test,Y_pred_test)\n",
    "\n",
    "print('ROC AUC : {:.4f}'.format(ROC_AUC))\n",
    "\n",
    "#### Support Vector classifier\n",
    "### Kernal= sigmoid\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='sigmoid',gamma='scale')\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "### Y predictions\n",
    "Y_pred_train = clf.predict(x_train)\n",
    "Y_pred_test  = clf.predict(x_test)\n",
    "\n",
    "# accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "ac1 = accuracy_score(y_train, Y_pred_train)\n",
    "print(\"Training Accuracy score:\", (ac1*100).round(2))\n",
    "ac2 = accuracy_score(y_test, Y_pred_test)\n",
    "print(\"Test Accuracy score:\", (ac2*100).round(2))\n",
    "print('Variaance between test and train accuracy',(ac1-ac2).round(2))\n",
    "\n",
    "# plot confusion matrix to describe the performance of classifier.\n",
    "cm_df=cm(y_test, Y_pred_test)\n",
    "class_label = [\"No\", \"Yes\"]\n",
    "df_cm = pd.DataFrame(cm_df, index = class_label, columns = class_label)\n",
    "sns.heatmap(df_cm, annot = True, fmt = \"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.show()\n",
    "\n",
    "#ROC Curve\n",
    "from sklearn.metrics import confusion_matrix as cm, accuracy_score as ac, classification_report as report,\\\n",
    "roc_curve, roc_auc_score , recall_score , precision_score, f1_score\n",
    "fpr, tpr, thresholds = roc_curve(y_test, Y_pred_test)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, linewidth=2, color='red')\n",
    "plt.plot([0,1], [0,1], 'k--' )\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for SVM Classifier using Polynomial Kernel for Predicting Size_category')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.show()\n",
    "ROC_AUC = roc_auc_score(y_test,Y_pred_test)\n",
    "\n",
    "print('ROC AUC : {:.4f}'.format(ROC_AUC))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
