{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Importing Dataset\n",
    "df=pd.read_csv(\"D:/Assignment and data set/book.csv\")\n",
    "df\n",
    "\n",
    "df.head()\n",
    "df.tail()\n",
    "#Data Exploration\n",
    "#Descriptive Statistics\n",
    "df.describe()\n",
    "df.info()\n",
    "#Missing Values\n",
    "df.isnull().sum()\n",
    "#Duplicated Values\n",
    "df.duplicated().sum()\n",
    "#columns\n",
    "df.columns\n",
    "\n",
    "#Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#plot histgraph\n",
    "for i in df.columns:\n",
    "    data=df.copy()\n",
    "    data[i].hist(bins=10)\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(i)\n",
    "    plt.show()\n",
    "\n",
    "#Pie chart\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.pie(df.sum(),\n",
    "       labels=df.columns,\n",
    "       explode = [0.0,0.0,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "       autopct= '%.2f%%',\n",
    "       shadow= True,\n",
    "       startangle= 190,\n",
    "       textprops = {'size':'large',\n",
    "                   'fontweight':'bold',\n",
    "                    'rotation':'0',\n",
    "                   'color':'black'})\n",
    "#plt.legend(loc= 'best')\n",
    "plt.title(\"Books Purchase Rate\", fontsize = 18, fontweight = 'bold')\n",
    "plt.show()\n",
    "\n",
    "#Association rules with 15% Support and 40% confidence\n",
    "from mlxtend.frequent_patterns import apriori,association_rules\n",
    "frequent_itemsets = apriori(df, min_support=0.15, use_colnames=True)\n",
    "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "frequent_itemsets\n",
    "frequent_itemsets.shape\n",
    "\n",
    "\n",
    "#with 40% Confidence\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.4)\n",
    "rules\n",
    "rules.shape\n",
    "list(rules)\n",
    "\n",
    "#shorting the rules in ascending \n",
    "rules.sort_values('lift',ascending = False)\n",
    "\n",
    "#shorting the rules in ascending with 20 \n",
    "rules.sort_values('lift',ascending = False)[0:20]\n",
    "\n",
    "# Lift Ratio > 1 is a good influential rule in selecting the associated transactions\n",
    "lift=rules[rules.lift>1]\n",
    "lift\n",
    "\n",
    "# visualization of obtained rule\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.scatter(rules['support'],rules['confidence'])\n",
    "plt.xlabel('support')\n",
    "plt.ylabel('confidence') \n",
    "plt.show()\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 15)\n",
    "wordcloud = WordCloud(background_color = 'white', width = 1200,  height = 1200, max_words = 121).generate(str(data.sum()))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.title('Items',fontsize = 20)\n",
    "plt.show()\n",
    "\n",
    "#Histogram is support to flot the value confidence and lift\n",
    "rules[['support','confidence','lift']].hist()\n",
    "\n",
    "#Scatter plot between support and confidence \n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(rules['support'], rules['confidence'])\n",
    "plt.show()\n",
    "\n",
    "#scatter plot between support and confidence using seborn\n",
    "import seaborn as sns\n",
    "sns.scatterplot('support', 'confidence', data=rules, hue='antecedents')\n",
    "plt.show()\n",
    "\n",
    "#Association rules with 20% Support and 60% confidence\n",
    "frequent_itemsets = apriori(df, min_support=0.2, use_colnames=True)\n",
    "frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "frequent_itemsets\n",
    "frequent_itemsets.shape\n",
    "\n",
    "#with 60% Confidence\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=0.6)\n",
    "rules\n",
    "rules.shape\n",
    "list(rules)\n",
    "\n",
    "#shorting the rules in ascending \n",
    "rules.sort_values('lift',ascending = False)\n",
    "\n",
    "#shorting the rules in ascending with 20 \n",
    "rules.sort_values('lift',ascending = False)[0:20]\n",
    "\n",
    "#Lift Ratio <2 is a good influential rule in selecting the associated transactions\n",
    "lift = rules[rules.lift<2]\n",
    "lift\n",
    "# visualization of obtained rule\n",
    "plt.figure(figsize=(16,9))\n",
    "plt.scatter(rules['support'],rules['confidence'])\n",
    "plt.xlabel('support')\n",
    "plt.ylabel('confidence') \n",
    "plt.show()\n",
    "\n",
    "#Histogram for support , cinfidence and lift\n",
    "rules[['support','confidence','lift']].hist()\n",
    "\n",
    "#Scatter plot between support and confidence \n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(rules['support'], rules['confidence'])\n",
    "plt.show()\n",
    "\n",
    "#scatter plot between support and confidence using seborn\n",
    "import seaborn as sns\n",
    "sns.scatterplot('support', 'confidence', data=rules, hue='antecedents')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
