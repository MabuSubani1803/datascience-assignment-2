{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Importing Dataset\n",
    "Fraud_check=pd.read_csv(\"D:/Assignment and data set/Fraud_check.csv\")\n",
    "Fraud_check\n",
    "\n",
    "Fraud_check.head()\n",
    "Fraud_check.tail()\n",
    "\n",
    "# Feature Engineering\n",
    "# Converting taxable_income <= 30000 as \"Risky\" and others are \"Good\"\n",
    "df=Fraud_check.copy()\n",
    "df['taxable_category'] = pd.cut(x = df['Taxable.Income'], bins = [10002,30000,99620], labels = ['Risky', 'Good'])\n",
    "df.head()\n",
    "#Data Exploration\n",
    "#Descriptive Statistics\n",
    "df.describe()\n",
    "df.info()\n",
    "#Missing Values\n",
    "df.isnull().sum()\n",
    "#Duplicated Values\n",
    "df.duplicated().sum()\n",
    "#columns\n",
    "df.columns\n",
    "\n",
    "#Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.countplot(x='Marital.Status',data=df)\n",
    "\n",
    "sns.pairplot(Fraud_check)\n",
    "\n",
    "#Boxplot\n",
    "ot=df.copy() \n",
    "fig, axes=plt.subplots(3,1,figsize=(14,6),sharex=False,sharey=False)\n",
    "sns.boxplot(x='Taxable.Income',data=ot,palette='crest',ax=axes[0])\n",
    "sns.boxplot(x='City.Population',data=ot,palette='crest',ax=axes[1])\n",
    "sns.boxplot(x='Work.Experience',data=ot,palette='crest',ax=axes[2])\n",
    "plt.tight_layout(pad=2.0)\n",
    "\n",
    "# Having a look at the correlation matrix\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "sns.heatmap(df.corr(), annot=True, fmt='.1g', cmap=\"viridis\", cbar=False, linewidths=0.5, linecolor='black')\n",
    "\n",
    "#piechart\n",
    "plt.figure(figsize = (12,8))\n",
    "plt.pie(df['taxable_category'].value_counts(),\n",
    "       labels=df.taxable_category.unique(),\n",
    "       explode = [0.07,0.0],\n",
    "       autopct= '%.2f%%',\n",
    "       shadow= True,\n",
    "       startangle= 190,\n",
    "       textprops = {'size':'large',\n",
    "                   'fontweight':'bold',\n",
    "                    'rotation':'0',\n",
    "                   'color':'black'})\n",
    "plt.legend(loc= 'upper right')\n",
    "plt.title(\"Class Type Distribution Pie Chart\", fontsize = 18, fontweight = 'bold')\n",
    "plt.show()\n",
    "\n",
    "#Data Pre-Processing\n",
    "\n",
    "data = df.copy()\n",
    "data.rename(columns={'Marital.Status':'Marital_Status', 'Taxable.Income':'Taxable_Income','Work.Experience':'Work_Experience','City.Population':'City_Population'}, inplace = True)\n",
    "data.drop('Taxable_Income', axis=1, inplace = True)\n",
    "categorical_features = data.describe(include=[\"object\",'category']).columns\n",
    "categorical_features\n",
    "\n",
    "#Creating dummy vairables of the categorical features\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for col in categorical_features:\n",
    "        le.fit(data[col])\n",
    "        data[col] = le.transform(data[col])\n",
    "data.head()\n",
    "\n",
    "#Data Pre-processing for feature Selection\n",
    "data_ = df.copy()\n",
    "data_.drop('Taxable.Income',axis=1, inplace =True)\n",
    "data_ = pd.get_dummies(data_.iloc[:,:-1])\n",
    "data_.head()\n",
    "\n",
    "data_['Taxable_Income'] = df.taxable_category\n",
    "data_.head()\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(data_[\"Taxable_Income\"])\n",
    "data_[\"Taxable_Income\"]=le.transform(data_[\"Taxable_Income\"])\n",
    "data_.head()\n",
    "\n",
    "# split into input (X) and output (y) variables\n",
    "\n",
    "x = data_.iloc[:, :-1]\n",
    "\n",
    "y=  data_.Taxable_Income\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=0,stratify=y)\n",
    "print(\"Shape of X_train: \",x_train.shape)\n",
    "print(\"Shape of X_test: \", x_test.shape)\n",
    "print(\"Shape of y_train: \",y_train.shape)\n",
    "print(\"Shape of y_test\",y_test.shape)\n",
    "\n",
    "\n",
    "# Random Forest \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFC = RandomForestClassifier(\n",
    "                  n_estimators=150,\n",
    "                  max_samples=0.9,\n",
    "                  max_features=0.3,\n",
    "                  random_state=6)\n",
    "\n",
    "\n",
    "# Model Fitting\n",
    "RFC.fit(x_train,y_train)\n",
    "Y_pred_train = RFC.predict(x_train)\n",
    "Y_pred_test = RFC.predict(x_test)\n",
    "\n",
    "#Finding test and train accuracy score \n",
    "from sklearn.metrics import accuracy_score\n",
    "acc1 = accuracy_score(y_train, Y_pred_train)\n",
    "print(\"Training Accuracy:\", (acc1).round(2))\n",
    "acc2 = accuracy_score(y_test, Y_pred_test)\n",
    "print(\"Test Accuracy:\", (acc2).round(2))\n",
    "\n",
    "\n",
    "#Bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "bag = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
    "                  n_estimators=200,\n",
    "                  max_samples=0.7,\n",
    "                  max_features=0.4,\n",
    "                  random_state=10)\n",
    "bag.fit(x_train,y_train)\n",
    "\n",
    "# Model Fitting\n",
    "Y_pred_train = bag.predict(x_train)\n",
    "Y_pred_test = bag.predict(x_test)\n",
    "\n",
    "#Finding test and train accuracy score\n",
    "from sklearn.metrics import accuracy_score\n",
    "acc1 = accuracy_score(y_train, Y_pred_train)\n",
    "print(\"Training Accuracy:\", (acc1).round(2))\n",
    "acc2 = accuracy_score(y_test, Y_pred_test)\n",
    "print(\"Test Accuracy:\", (acc2).round(2))\n",
    "\n",
    "# Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "GBR = GradientBoostingRegressor(n_estimators=100,\n",
    "                  learning_rate=0.1,\n",
    "                  max_features=0.7,\n",
    "                  random_state=10)\n",
    "GBR.fit(x_train,y_train)\n",
    "\n",
    "# Model Fitting\n",
    "Y_pred_train = GBR.predict(x_train)\n",
    "Y_pred_test = GBR.predict(x_test)\n",
    "\n",
    "#Finding test and train accuracy score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "err1 = np.sqrt(mean_squared_error(y_train, Y_pred_train))\n",
    "print(\"Gradient Boosting-Training Error:\", (err1).round(2))\n",
    "err2 = np.sqrt(mean_squared_error(y_test, Y_pred_test))\n",
    "print(\"Gradient Boosting-Test Error:\", (err2).round(2))\n",
    "print(\"Variance Between Train and Test:\",(err2-err1).round(2))\n",
    "\n",
    " \n",
    "#ada boost regressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "ABR = AdaBoostRegressor(n_estimators=100,base_estimator=None,\n",
    "                  learning_rate=0.)\n",
    "GBR.fit(x_train,y_train)\n",
    "Y_pred_train = ABR.predict(x_train)\n",
    "Y_pred_test = ABR.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "err1 = np.sqrt(mean_squared_error(y_train, Y_pred_train))\n",
    "print(\"Gradient Boosting-Training Error:\", (err1).round(2))\n",
    "err2 = np.sqrt(mean_squared_error(y_test, Y_pred_test))\n",
    "print(\"Gradient Boosting-Test Error:\", (err2).round(2))\n",
    "print(\"Variance Between Train and Test:\",(err2-err1).round(2))\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "#Grid Search CV\n",
    "d1={'n_estimators':[50,150,200,250],\n",
    "    'max_samples':[0.1,0.5,0.7,0.9],\n",
    "    'max_features':[0.3,0.5,0.7,0.9],\n",
    "    'random_state':[2,6,8,10]}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid=GridSearchCV(estimator=RFC, param_grid=d1)\n",
    "grid.fit(x_train,y_train)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
