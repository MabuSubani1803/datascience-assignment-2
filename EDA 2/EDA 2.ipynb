{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import ppscore as pps\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('C:/Users/HP PROBOOK/Downloads/EDA2/EDA2/adult_with_headers.csv')\n",
    "\n",
    "# Data Exploration and Preprocessing\n",
    "\n",
    "# Basic data exploration\n",
    "print(\"Summary Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handle missing values (e.g., imputation or removal)\n",
    "# Example:\n",
    "# df.dropna(inplace=True)\n",
    "\n",
    "# Encoding Techniques\n",
    "\n",
    "# One-Hot Encoding for categorical variables with less than 5 categories\n",
    "onehot_encoder = OneHotEncoder(drop='first', sparse=False)\n",
    "for column in df.select_dtypes(include='object').columns:\n",
    "    if df[column].nunique() < 5:\n",
    "        encoded_features = onehot_encoder.fit_transform(df[[column]])\n",
    "        df_encoded = pd.concat([df, pd.DataFrame(encoded_features, columns=onehot_encoder.get_feature_names_out([column]))], axis=1)\n",
    "        df = df_encoded.drop(columns=[column])\n",
    "\n",
    "# Label Encoding for categorical variables with more than 5 categories\n",
    "label_encoder = LabelEncoder()\n",
    "for column in df.select_dtypes(include='object').columns:\n",
    "    if df[column].nunique() > 5:\n",
    "        df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "# Apply scaling techniques to numerical features\n",
    "\n",
    "# Standard Scaling\n",
    "scaler_standard = StandardScaler()\n",
    "df[df.select_dtypes(include=np.number).columns] = scaler_standard.fit_transform(df.select_dtypes(include=np.number))\n",
    "\n",
    "# Min-Max Scaling\n",
    "scaler_minmax = MinMaxScaler()\n",
    "df[df.select_dtypes(include=np.number).columns] = scaler_minmax.fit_transform(df.select_dtypes(include=np.number))\n",
    "\n",
    "# Feature Engineering\n",
    "\n",
    "# Create new features\n",
    "# Example:\n",
    "# df['new_feature_1'] = df['feature_1'] + df['feature_2']\n",
    "# df['new_feature_2'] = df['feature_3'] * df['feature_4']\n",
    "\n",
    "# Apply transformation to skewed numerical feature\n",
    "# Example:\n",
    "# df['skewed_feature'] = np.log(df['skewed_feature'])\n",
    "\n",
    "# Feature Selection\n",
    "\n",
    "# Use Isolation Forest algorithm to identify and remove outliers\n",
    "isolation_forest = IsolationForest()\n",
    "outliers = isolation_forest.fit_predict(df.select_dtypes(include=np.number))\n",
    "df_no_outliers = df[outliers != -1]\n",
    "\n",
    "# Discuss how outliers can affect model performance.\n",
    "# Outliers can skew the distribution and affect the mean and standard deviation, leading to biased model predictions.\n",
    "\n",
    "# Apply PPS to find and discuss relationships between features\n",
    "pps_matrix = pps.matrix(df)\n",
    "print(\"\\nPPS Matrix:\")\n",
    "print(pps_matrix)\n",
    "\n",
    "# Compare its findings with the correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(correlation_matrix)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
