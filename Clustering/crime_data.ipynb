{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Importing Dataset\n",
    "df=pd.read_csv(\"D:/Assignment and data set/crime_data.csv\")\n",
    "df\n",
    "\n",
    "#Data Exploration\n",
    "#Descriptive Statistics\n",
    "df.describe()\n",
    "\n",
    "df.info()\n",
    "#Missing Values\n",
    "df.isnull().sum()\n",
    "#Duplicated Values\n",
    "df.duplicated().sum()\n",
    "#columns\n",
    "df.columns\n",
    "#Exploratory Data Analysis\n",
    "#imported matplot for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# correlation heatmap\n",
    "f,ax = plt.subplots(figsize=(18,12))\n",
    "sns.heatmap(df.corr(), annot=True, linewidths =.5, fmt ='.1f',ax=ax)\n",
    "plt.show()\n",
    "\n",
    "#plot histgraph\n",
    "for i in df.columns:\n",
    "    data=df.copy()\n",
    "    data[i].hist(bins=10)\n",
    "    plt.ylabel('Count')\n",
    "    plt.title(i)\n",
    "    plt.show()\n",
    "\n",
    "#boxplot\n",
    "ot=df.copy() \n",
    "fig, axes=plt.subplots(4,1,figsize=(12,8),sharex=False,sharey=False)\n",
    "sns.boxplot(x='Murder',data=ot,palette='crest',ax=axes[0])\n",
    "sns.boxplot(x='Assault',data=ot,palette='crest',ax=axes[1])\n",
    "sns.boxplot(x='UrbanPop',data=ot,palette='crest',ax=axes[2])\n",
    "sns.boxplot(x='Rape',data=ot,palette='crest',ax=axes[3])\n",
    "plt.tight_layout(pad=2.0)\n",
    "\n",
    "#finding outlier\n",
    "def outlier_function(df,col):\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3-q1    \n",
    "    upper = q3+(1.5*iqr)\n",
    "    lower = q1-(1.5*iqr)\n",
    "    return lower,upper\n",
    "outlier_function(df,'Rape')\n",
    "outlier_function(df,'UrbanPop')\n",
    "outlier_function(df,'Assault')\n",
    "outlier_function(df,'Murder')\n",
    "\n",
    "#\n",
    "sns.set_style(style='darkgrid')\n",
    "sns.pairplot(df)\n",
    "\n",
    "#Splitting of x and y\n",
    "x = df.iloc[:,1:]\n",
    "\n",
    "\n",
    "#Data Transformations\n",
    "#improting  StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "for column in df.columns:\n",
    "    if df[column].dtype=='object':\n",
    "        continue\n",
    "    df[column]=ss.fit_transform(df[[column]])\n",
    "df\n",
    "\n",
    "#Hierarchical clustering\n",
    "#Merthod=single\n",
    "#Dendograms\n",
    "import scipy.cluster.hierarchy as shc\n",
    "plt.figure(figsize=(10, 7))  \n",
    "plt.title(\"Customer Dendograms\")  \n",
    "dend = shc.dendrogram(shc.linkage(x, method='single'))\n",
    "\n",
    "#AgglomerativeClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster = AgglomerativeClustering(n_clusters=4, affinity='euclidean', linkage='single')\n",
    "Y = cluster.fit_predict(x)\n",
    "Y\n",
    "\n",
    "#creating Y dataframe\n",
    "Y_new = pd.DataFrame(Y) \n",
    "#Y value counts\n",
    "Y_new.value_counts() \n",
    "\n",
    "#Method = complete\n",
    "#Dendograms\n",
    "import scipy.cluster.hierarchy as shc\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(30,15))  \n",
    "plt.title(\"Customer Dendograms\")  \n",
    "dend = shc.dendrogram(shc.linkage(x, method='complete'))\n",
    "\n",
    "#AgglomerativeClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='complete')\n",
    "Y = cluster.fit_predict(x)\n",
    "Y\n",
    "#creating Y dataframe\n",
    "Y_new = pd.DataFrame(Y)  \n",
    "# Y value counts\n",
    "Y_new.value_counts()  \n",
    "\n",
    "\n",
    "#Method = averagee\n",
    "#Dendograms\n",
    "import scipy.cluster.hierarchy as shc\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(30,15))  \n",
    "plt.title(\"Customer Dendograms\")  \n",
    "dend = shc.dendrogram(shc.linkage(x, method='average'))\n",
    "\n",
    "#AgglomerativeClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='average')\n",
    "Y = cluster.fit_predict(x)\n",
    "Y\n",
    "#creating Y dataframe\n",
    "Y_new = pd.DataFrame(Y)  \n",
    "# Y value counts\n",
    "Y_new.value_counts()  \n",
    "\n",
    "''' For AgglomerativeClustering i tried with all the three different methods \n",
    "    such as single , complete and average. Amoung these methods complete linkage \n",
    "    is best clusers '''\n",
    "\n",
    "\n",
    "\n",
    "#Initializing KMeans clustering\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=5,n_init=20)\n",
    "#Fitting with inputs\n",
    "kmeans = kmeans.fit(x) \n",
    "# Predicting the clusters\n",
    "Y = kmeans.predict(x)\n",
    "#creating Y dataframe\n",
    "Y_new = pd.DataFrame(Y) \n",
    "#Y value counts\n",
    "Y_new.value_counts()  \n",
    "\n",
    "#Total with in centroid sum of squares \n",
    "kmeans.inertia_\n",
    "\n",
    "clust = []\n",
    "for i in range(1,11):\n",
    "    kmeans = KMeans(n_clusters=i,random_state=0)\n",
    "    kmeans.fit(x)\n",
    "    clust.append(kmeans.inertia_)\n",
    "\n",
    "#Elbow method \n",
    "plt.scatter(x=range(1,11), y=clust,color='red')\n",
    "plt.plot(range(1,11), clust,color='black')\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('inertial values')\n",
    "plt.show()\n",
    "\n",
    "# DBSCAN\n",
    "X = df.iloc[:,1:].values \n",
    "X\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "dbscan = DBSCAN(eps=3, min_samples=5)\n",
    "#fitting dbscan\n",
    "dbscan.fit(X) \n",
    "\n",
    "Y = dbscan.labels_\n",
    "pd.DataFrame(Y).value_counts()\n",
    "\n",
    "### creating cluster id with dataframe\n",
    "df[\"Cluster id\"] = pd.DataFrame(Y)\n",
    "df.head()\n",
    "\n",
    "#Checking the noise points\n",
    "noise_points = df[df[\"Cluster id\"] == -1]\n",
    "noise_points\n",
    "\n",
    "#final data\n",
    "Finaldata = df[(df[\"Cluster id\"] == 0)| (df[\"Cluster id\"] == 1)\n",
    "               |(df[\"Cluster id\"] == 2)].reset_index(drop=True)\n",
    "Finaldata\n",
    "\n",
    "\"\"\"\n",
    "For DBSCAN i have taken eps=3 because below 3 more noise points are occuring which \n",
    "i do not want that much of outliers after that i kept the noise points out and prepared\n",
    " a new final data which has other cluster ids 0's,1's and 2's and kept them in a correct indexing\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
